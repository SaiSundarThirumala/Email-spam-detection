{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  lab\n",
       "0      ham  Go until jurong point, crazy.. Available only ...    0\n",
       "1      ham                      Ok lar... Joking wif u oni...    0\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...    1\n",
       "3      ham  U dun say so early hor... U c already then say...    0\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\SUNDAR\\\\Desktop\\\\codes\\\\major project\\\\spam.csv\",encoding = 'latin1')\n",
    "\n",
    "data['lab'] = data[\"Category\"].replace({\"ham\":0,\"spam\":1})\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.Message\n",
    "Y = data.Category\n",
    "le = LabelEncoder()#converts categorical variables to numverical format\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting into words using tokenization\n",
    "#tokens- words\n",
    "max_words = 1000\n",
    "max_len  = 150\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen = max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding layer - used for neural networks on text data.It input data be integer\n",
    "#each word is encoded as unique integer...it can be used to load a pre-trained word embedding model- a type of transfer learning\n",
    "def rnn():\n",
    "    inputs = Input(name = 'inputs',shape = [max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name = 'FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name = 'out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs = inputs, outputs = layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 150, 50)           50000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                29440     \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96337 (376.32 KB)\n",
      "Trainable params: 96337 (376.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = rnn()\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(),metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 37s 761ms/step - loss: 0.3947 - accuracy: 0.8640 - val_loss: 0.2194 - val_accuracy: 0.9092\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 14s 515ms/step - loss: 0.1553 - accuracy: 0.9565 - val_loss: 0.1077 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 14s 499ms/step - loss: 0.0777 - accuracy: 0.9806 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 12s 443ms/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 0.0649 - val_accuracy: 0.9821\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 266ms/step - loss: 0.0467 - accuracy: 0.9877 - val_loss: 0.0638 - val_accuracy: 0.9809\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 7s 266ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.0590 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 301ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 0.0959 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2468814bd10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calllback is a set of function to be applied at given stages of the training procedure.\n",
    "#can use callback to get a view on internal states and statistics of the model during training\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs = 10,\n",
    "          validation_split=0.2, callbacks=[EarlyStopping(monitor = 'val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen = max_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0745 - accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = [input()]\n",
    "\n",
    "textx = tok.texts_to_sequences(test_content)\n",
    "textx = sequence.pad_sequences(textx,maxlen=max_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "[[0.99921185]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(textx)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Spam mail\n"
     ]
    }
   ],
   "source": [
    "if pred > [[0.5]]:\n",
    "    print(\"This is a Spam mail\")\n",
    "else:\n",
    "    print(\"This is not a Spam mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\SUNDAR\\\\Desktop\\\\codes\\\\major project\\\\spam.csv\",encoding = 'latin1')\n",
    "\n",
    "data['lab'] = data[\"Category\"].replace({\"ham\":0,\"spam\":1})\n",
    "data.head()\n",
    "\n",
    "X = data.Message\n",
    "Y = data.Category\n",
    "le = LabelEncoder()#converts categorical variables to numverical format\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.20)\n",
    "\n",
    "#spliting into words using tokenization\n",
    "#tokens- words\n",
    "max_words = 1000\n",
    "max_len  = 150\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen = max_len)\n",
    "\n",
    "#Embedding layer - used for neural networks on text data.It input data be integer\n",
    "#each word is encoded as unique integer...it can be used to load a pre-trained word embedding model- a type of transfer learning\n",
    "def rnn():\n",
    "    inputs = Input(name = 'inputs',shape = [max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name = 'FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name = 'out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs = inputs, outputs = layer)\n",
    "    return model\n",
    "\n",
    "model = rnn()\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(),metrics = ['accuracy'])\n",
    "\n",
    "#calllback is a set of function to be applied at given stages of the training procedure.\n",
    "#can use callback to get a view on internal states and statistics of the model during training\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs = 10,\n",
    "          validation_split=0.2, callbacks=[EarlyStopping(monitor = 'val_loss',min_delta=0.0001)])\n",
    "\n",
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen = max_len) \n",
    "\n",
    "acc = model.evaluate(test_sequences_matrix,Y_test)\n",
    "\n",
    "test_content = input()\n",
    "textx = tok.texts_to_sequences(test_content)\n",
    "textx = sequence.pad_sequences(textx,maxlen=max_len)\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')  # Create an HTML file for the form\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        message = request.form['message']\n",
    "        textx = tok.texts_to_sequences([message])\n",
    "        textx = sequence.pad_sequences(textx, maxlen=max_len)\n",
    "        pred = model.predict(textx)\n",
    "\n",
    "        if pred > 0.05:\n",
    "            result = \"This is a Spam mail\"\n",
    "        else:\n",
    "            result = \"This is not a Spam mail\"\n",
    "\n",
    "        return render_template('result.html', result=result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
